# September

## September 4th

### Notes:
Today I began refactoring the hazard unit testbench. This module is very important to the execution of the whole system, so it's very important that it is thoroughly verified, especially with the complications included through the addition of the instruction cache, and branch predictor. 

To start, I decided it would be best to make use of more tasks, one for each expected case I wanted to test. In this way I can make each case I want to test it's own block of code that can be updated as needed. This extra organization should make future changes much easier to verify. 

Each scenario will have a driver task, which will set **only** the related signals, and a checker task that will assert the expected results. The scenario drivers can be combined to test when multiple hazards may overlap (like a load stall, and cache miss at the same time), however these combined scenarios will require their own checker tasks to handle priority.

Today was a short day, so I essentially just made this decision, and layed out some of the tasks that need to be created within the hazard unit testbench. Note that this kind of refactor will not be done for most testbenches, however I feel it is worth it for this one, as the hazard signals are so important in how the processor functions.

### Summary
- Decided on testing method for hazard unit
- Layed out tasks to create
  
## September 6th

### Notes:
Today I implemented the changes to the hazard unit tb. This ended up being a pretty split development. I created some drive* tasks for simple situations, scenario* tasks for more complex situations, and then expect* tasks for both. Essentially, when a situation was multi-cycle, and dependant on a specfic scenario, it became a "scenario" task. When it was a simple combination input to output situation, it became a "drive" task. Ultimately, this ended up in the testbench being a bit messy, but it does confirm the functionality. I'm not trying to be incredibly rigorous with this testing, I just wanted it to be reliable. So I'm leaving it as is. I also didn't touch the forwarding checking, as that worked just fine, and had no changes made related to it.

I also created a macro that essentially acts as a function. It takes in a condition, a message, and 2 arguments. It asserts the condition, and if it fails it prints the message, including the 2 arguments in the string where applicable. This was added to the tb/common directory in a file called "tb_macros.sv", which from now on will contain tb related macros.

After the hazard TB was updated, I moved on to the other tests that were failing their tests. This mostly lead to testbenches being updated to reflect new expected behaviour. However, in one case there was an issue with the RTL. While debugging the branching buffer, it was found that the local predictors were behaving incorrectly. This was because of how the output was being assigned, how the newstate was being determined, and how the present state was being assigned. To say the least, it revealed a number of important issues in the RTL, which were then fixed.

I also updated some files to allow the regression parser to properly determine modules that contained parameters in their instantiation. The parser expects the module, as well as the instance name on the same line, however my current instantiation style for modules with parameters has the module name a couple of lines above the instance name. To solve this, I added a hack, where I duplicate the instance name on the same line as the module name, allowing the parser to find the module name. This isn't ideal, but it is an easy fix, and will work well enough.

In addition to this, restyled all the testbenches to match the same module and signal instantiation/definition style as my RTL. The TB's themselves were not changed. I also updated some signals that pass only specific parts of a signal between module boundries as a specific name. For example, funct7b5 which represents the 7th bit of funct7 was just changed to funct7, and the 5th bit was then indexed within the module. This cleans up module boundries quite a bit, and improves clarity, both of which will be things that will be valuable as development continues.

### Summary:
- Fixed and updated hazard unit TB
- Fixed and updated all other failing test TB's
- Fixed issues in the local predictor RTL
- Fixed issues related to module parsing for compilation
- Updated TB module and signal style
- Changed single bit signals to pass whole signal, and index within module

## September 7th

### Notes:
Today I focused on changing all of my signal names to match the snake_case style I'm going for, as well as include pipeline stage, and i/o information more cleary. The style I decided on was: **<signal_name>_<pipeline_stage>_<i/o>**. Here, the i/o suffix is dependant on the scope of each module. So if a signal is an input to a module, it will have the _i suffix, if it is an output it will have the _o suffix, and if it is an internal signal, it will have neither suffix. This should Ideally provide clarity when debugging, as it will be clear that a signal is either internal to the module, an input, or an output.

To do this I created a script. This script takes in a csv file in the format <old_signal_name>,<new_signal_name>. It does two passes of the input files, one to create a renaming map, and one to apply the changes, and either write to a new file, or overwrite the old one. The renaming map determines what old signals that need to be renamed exist in the module, and what their new name is to be, taking into account suffixes. Note that in my design, signals are already specifed by pipeline stage, ending with F for fetch stage, D for decode stage, etc. When I say that my script takes suffixes into account, I mean it will transfer this F into the properly stlyed _f, and additionally add _i or _o, if the signal is an input or output signal for a given module.

For example, say I want to do the rename (OldSignal,new_signal), and lets say this old signal is specified as being an F stage signal, and is an input for a given module. This means that the old signal is named OldSignalF. My script will find this signal, see it is an F stage signal, and an input, and therefore have it's new name mapped as **new_signal_f_i** for that specific module.

Once all signals are remapped, the second pass uses regex operations to search for the old signal names, and replace them with the new mapped name. 

Some extra complexity is added by module instantiations, as some modules may have different port names when compared to the instantiating module (internal signal for top, port for instantiated). To handle this, I made it so that the instantiated modules renaming map is used for the ports while it is being instantiated, while keeping the top modules renaming map used for the signals connected to the ports. This is agian done using regex operations.

Ultimately it ended up working quite well, and changing all the signals accordingly. It can also act as a style enforcer for the _i and _o suffixes. If the new_signal_name and old_signal_name are the same, it will just update the signals to match the _i and _o style guideline, which is nice to have!

### Summary:
- Created script to update all signal names in project
- Used script to update all signal names in project

## September 8th

### Notes:
Today I looked at adding enum types and macros into my design to improve readibility. I started with deciding what I wanted to be an enum, and what I wanted to be a macro. This is what I've decided on as of now:
Enum:
  - funct3 -> individual enum type for each type of instruction for clarity
  - Control signals
Macros:
  - Opcodes
  - funct7 -> only have two valid values for implemented instruction

I feel that this will provide plenty of clarity in the code itself, and having control signals and funct3 show up with descriptive names in the wave viewer will be game changer. The opcodes aren't used in many locations, but it will be good for them to have descriptive names where they do appear, I just thought the overhead of an enum type for the opcodes wasn't worth it.

Aside from deciding the general direction for implementing these features into the design, I also created the package for funct3 as a start. It hasn't been implemented or tested, as today was a short session.

### Summary:
- Determined plan for macros and enum type implementation
- Created funct3 package

## September 13th

### Notes:
Today I decided to switch over to using macros for essentially everything global rather than enum types. This is because the benifits of enum types ended up being outweighed by the overhead of implementing them properly. Because of this I made the following macros:
- Opcodes
- funct7
- funct3
  - Done for each instruction utilizing funct 3 for clarity
- control signals

I made two seperate macro files:
- instr_macros.sv: Contains macros for opcodes, funct3 and funct7
- control_macros.sv: Contains macros for control signals

These macros were mainly implemented in modules related to the decoding stage, but were also added elsewhere. In the pipeline stage modules, some muxes were replaced with case statements so that the macros could be used in order to provide more clarity, maintainability, and scalability, as now these macros can be changed in one location without needing to worry about the implications of multiplexers in the datapath, and the multiplexers can easily be extended as needed by adding another case. I may end up replacing all multiplexer modules with case statements, but that was not done today.

The macros were also added for decoding in the ALU, and in the instr_cache_ctlr module in order to improve clarity of one of the logic equations used. The logic equation in questions form was also changed, and verified to be the same as before, which was done to provide more clarity.

In addition to the macros, enum types were added to the local state machines throughout the project. These included the instr_cache_ctlr state machine, the local predictors, and the ghr. While this was done, the state machines were also cleaned up, and made to follow standard state machine implementation conventions. Each one now has an always block for determining the next state, and updating the new state. 

These changes made the RTL code far more self documenting, and will surely help in debugging as the scale of the design increases.

### Summary:
- Created macros for various signals
- Replaced magic numbers with macros where applicable
- Replaced some multiplexer modules with case statements to take advantage of macros
- Added enum types to state machines
- Cleaned up RTL of state machines

## September 14th/17th

### Notes:
This is a combined entry because I did not log my progress on the 14th. Over these two days I focused on verifying my design, both with and without the I-cache implemented and used. To do this, I updated my instruction memory model to include the same output signals as my instruction cache. These signals were just tied to the values they would have been on a cache hit, meaning that it will never need to deal with miss conditions. After this was done, I tested the programs to ensure that the processor worked as it did previously with all my risc-v programs. This required some small fixes to some errors that were introduced during some of my previous refactoring. I also updated the regression framework to allow for passing of defines by adding them to the config file, and I updated the script to run all my hand-made risc-v tests when running the integration test.

Once this was done, I made a simple memory model to store information for my cache to retrieve data from. It loads in information from a hex file, and whenever there is a cache miss, it starts sending data to the cache starting the **next** cycle, and continues sending data until the miss signal goes low. It achieves this through a 2-state FSM, one where there is no request, where it indicates that no replacement is ready, and doesn't send any data, and another it sets signals to retrieve the appropraite data from the internal memory array. In the state where data is being sent, a counter is incremented every cycle until the miss signal goes low. This works properly because when all the appropriate signals are high, the cache can accept a new word every cycle.

That said, once this was all implemented, I tested the top level integration tests with the i-cache being used. After some fixes to the memory model, ensuring the cache was populated properly, all existing directed tests passed! These tests are not exhaustive, however they do show that it can run all instructions, and handle branches, and multiple cache fills. More directed tests designed to really stress the processor will need to be created.

### Summary:
- Allowed for top level testbench to use both simple instr mem, and the instr cache
- Updated regression script to accomodate integration testing
- Created a main memory model
- Integrated main memory model into top level module
  - Only defined when doing a simulation
- Fixed integration bugs
- Confirmed the processor passes all current directed tests with the I-cache integrated!

## September 20th

### Notes:
Today I focused on getting ym RISC-V tool chain setup properly, as this will allow for far easier and honestly better testing of the processor. To do this I essentially followed the directions for installing everything needed from the following git page: https://github.com/riscv-non-isa/riscv-arch-test.

I downloaded the riscv GNU tool chain, as well as everything else that will eventually be needed in order to run a full suite of compliance tests.

Once this was downloaded properly to compile for the rv32i instruction set, I began creating a new directory in test_inputs called compiled programs. I ended up making a simple linker script, that denotes an area for instructions, and an area for data. I also created a makefile that compiles all assembly and C programs recursively from the directory in which it is located. After everything is said and done, each program has a hex file compatible with my architecture for both the data and instruction memories. I then moved over, renamed, compiled, and retested all of my handmade risc-v assembly programs.

Once this was done, I made two more risc-v assembly programs that were created to test the corner cases of the i-cache and branch predictor interactions. These ended up passing, which is great! These did not really do a big stress test, however they do give a lot of confidence that the pipeline works as intended.

I refactored my regression script to make it more readable, and made it handle running top level integration tests much better. And I also began work on a monitor module that will be used to gather useful information on CPU performance during simulation

### Summary:
- Setup riscv compilation tool chain
- Downloaded compliance test files
- Converted old assembly programs to work with new tool chain
- Setup directory for program compilation and hex file generation
- Retested riscv programs
- Created new riscv test programs for cache and branch corner cases
- Updated regression script
- Started work on monitor modules

## September 26th

### Notes:
This section will cover all the work done since my last entry, which took place over a number of days. The main focus of this period was getting dhrystone to run as expected on my processor, which mostly invloved devloping a linker script, startup assembly program, and makefiles that allowed for proper compilation. Additionally, the cycle monitor module was completed.

Starting with an overview of the cycle monitor. The idea behind this module was to monitor the total cycle count, the retired instruction count, and keep a counter of each type of instruction retired. To determine if an instruction was actually retired, a valid flag was added to the pipeline.

This valid bit was set in the decode stage, receiving a 1 as an input to the decode stage pipeline register. This works becauseby default we assume a valid instruction is being input into the decode register. When a flush occurs, the valid bit is set low, as expected. When there is a stall, it remains connected to the valid instruction. This valid bit propogates through the pipeline, connected to the corrosponding instruction. Again this works, because flushes and stalls will remove or halt the valid bit along with the instruction, ensuring it is only high with a valid instruction.

Once the valid bit reaches the writeback stage, it is sent to the cycle monitor, along with stall_w (writeback stages stall signal). Within the cycle monitor, a signal, **retire_w** is only set high if the valid bit is high, and the stall bit is low, ensuring cycles in which the pipeline is stalled are not counted towards the retirement count. Every clock cycle the **retire_w** signal is high, the retired instruction count is incremented. Note the cycle count is incremented every cycle. As of now IPC is determined manually by viewing the signal values at the end of simulation, but this is planned to be changed to be determined, and logged automatically.

I also wanted a counter of each type of instruction that gets retired. To get this, the whole instruction word was propogated through the pipeline, so that it can be sent to the cycle monitor in the writeback stage. In the cycle monitor, a case statement is used to increment the count for a given instruction type when the opcode matches that instruction count. 

Also note that because the instruction word is sent, we can also monitor for NOP operations. When a NOP instruction word is found, the retirement counter is not incremented. This may slightly deflate the retirement count, as these NOPs are inserted by the compiler, but the inverse is that if a ton of NOP's were included, the retirement count would be inflated, as when a NOP is inserted, there's no chance of a stall, or flush occuring, making retirment count match cycle count for those operations.

Now on to the compilation flow changes. It took some iteration to meet the requirements I was looking for, but at this point, dhrystone is running properly, and initial IPC measurements have been taken using both the simple instruction memory model, and the I-cache. At this point, I can't actually get a dhrystone score, as my processor doesn't have an internal timer, or a UART setup to support printf. These unsupported functions were stubbed out in a seperate C file so that the test could still run properly with my current setup.

I will not cover the software compilation flow extensively here, as this is not the core focus of this project, but rather glue in order to allow for the core project to be usable. But again, the main updates were to the makefiles, assembly startup program and linker script.

The software compilation flow will still need some work to improve configurability, and to get proper benchmark scores, more functionality will need to be implemented.

As mentioned, initial IPC values for Dhrystone were found using the developed monitor module were as follows:
- simple Imem: 
  - IPC: 0.9026
  - CPI: 1.1079
- I-cache: 
  - IPC: 0.9019
  - CPI: 1.1088

I'm putting these here more as a show of progress, as mentioned above, I will begin generating logs that contain more extensive information.

### Summary:
- Completed cycle_monitor.sv module for measuring:
  - cycle count
  - retired instructions
  - instruction type count
- Updated software compilation flow
- Succsefully compiled and ran Dhrystone in simulation
- Measured initial IPC and CPI for both simple Imem and I-cache implementations 



Performance metrics to gather
- Total cycles
- Instructions retired
- IPC
- CPI
- Load stalls
- Branch misprediction penalty cycles
- Branches executed
- Branch mispredicts
- Branch misprediction rate
- I-cache misses
  - I-cache miss penalty cycles
- D-cache misses
  - D-cache miss penalty cycles
- AMAT (Average Memory Access Time)
- Instruction mix
  - ALU ops count
  - Loads count
  - Stores count
  - Branches/jumps cout